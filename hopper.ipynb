{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import imageio\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRewardWrapper(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(CustomRewardWrapper, self).__init__(env)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, truncated, info = self.env.step(action)\n",
    "        # Access relevant state and action variables\n",
    "        \n",
    "        #state\n",
    "        z = obs[0]                  # Height of the robot\n",
    "        a = obs[1]                  # Angle of the robot\n",
    "        a_hip = obs[2]              # Angle of the hip\n",
    "        a_knee = obs[3]             # Angle of the knee\n",
    "        a_ankle = obs[4]            # Angle of the ankle\n",
    "        v_x = obs[5]                # Velocity in x direction\n",
    "        v_z = obs[6]                # Velocity in z direction\n",
    "        a_d = obs[7]                # Angular velocity \n",
    "        a_hip_d = obs[8]            # Angular velocity of the hip\n",
    "        a_knee_d = obs[9]           # Angular velocity of the knee\n",
    "        a_ankle_d = obs[10]         # Angular velocity of the ankle\n",
    "        \n",
    "        #action\n",
    "        torque_hip = action[0]      # Torque applied to the hip\n",
    "        torque_knee = action[1]     # Torque applied to the knee\n",
    "        torque_ankle = action[2]    # Torque applied to the ankle\n",
    "\n",
    "        #different criteria for reward\n",
    "        energy_used = np.sum(np.square(action))  # Simplistic energy calculation\n",
    "\n",
    "        # Custom reward logic\n",
    "        custom_reward = z * 0.5                                     # Reward for height\n",
    "        custom_reward += np.tanh(a) * 0.5                           # Reward for positive angles\n",
    "        custom_reward += 5*np.exp(-(a-(2*np.pi))**2/(2*np.pi))      # Reward for 2pi angle\n",
    "        custom_reward -= energy_used * 0.01                         # Penalize energy consumption\n",
    "\n",
    "        # used by openai\n",
    "        # backroll = -obs[7]\n",
    "        # height = obs[0]\n",
    "        # vel_act = action[0] * obs[8] + action[1] * obs[9] + a[2] * obs[10]\n",
    "        # backslide = -obs[5]\n",
    "        # reward = backroll * (1.0 + .3 * height + .1 * vel_act + .05 * backslide)\n",
    "\n",
    "        if done:\n",
    "            custom_reward -= 8  # Heavy penalty for falling\n",
    "\n",
    "        return obs, custom_reward, done, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 45.1     |\n",
      "|    ep_rew_mean     | 12.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 959      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.7        |\n",
      "|    ep_rew_mean          | 15          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011493967 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | 0.0225      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.69        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 13.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 61.5        |\n",
      "|    ep_rew_mean          | 20.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 452         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013908952 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.15        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 77.6         |\n",
      "|    ep_rew_mean          | 31.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 430          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0132603645 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.2         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.1          |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0209      |\n",
      "|    std                  | 0.979        |\n",
      "|    value_loss           | 16.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 91.2         |\n",
      "|    ep_rew_mean          | 41.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 411          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103811985 |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | 0.707        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.16         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    std                  | 0.973        |\n",
      "|    value_loss           | 17.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 106         |\n",
      "|    ep_rew_mean          | 53.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008945545 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.08        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 12.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 123         |\n",
      "|    ep_rew_mean          | 65.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 378         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009053761 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.2        |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.984       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.987       |\n",
      "|    value_loss           | 7.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 137         |\n",
      "|    ep_rew_mean          | 77.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009794481 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.999       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 6.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 151         |\n",
      "|    ep_rew_mean          | 89.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009215974 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.812       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 3.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 166         |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 363         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010383477 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.17       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.803       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 2.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 184         |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012473011 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.67        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 2.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 199         |\n",
      "|    ep_rew_mean          | 125         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012102613 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.748       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 0.958       |\n",
      "|    value_loss           | 2.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 213         |\n",
      "|    ep_rew_mean          | 137         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008597029 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.12       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.68        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.955       |\n",
      "|    value_loss           | 2.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 225         |\n",
      "|    ep_rew_mean          | 146         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 355         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008200512 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.947       |\n",
      "|    value_loss           | 2.67        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 242         |\n",
      "|    ep_rew_mean          | 158         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 355         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009181104 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.09       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.166       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "healthy_reward = 0.8\n",
    "healthy_z_range = (0.2, float(\"inf\"))\n",
    "healthy_angle_range = (-np.pi/4, 2*np.pi+np.pi/4)\n",
    "reset_noise_scale = 5e-3\n",
    "exclude_current_positions_from_observation = True\n",
    "\n",
    "env = gym.make('Hopper-v4', render_mode='rgb_array', healthy_reward=healthy_reward, healthy_z_range=healthy_z_range, healthy_angle_range=healthy_angle_range, reset_noise_scale=reset_noise_scale, exclude_current_positions_from_observation=exclude_current_positions_from_observation)\n",
    "env = CustomRewardWrapper(env)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "n_learning_steps = 30000\n",
    "model.learn(total_timesteps=n_learning_steps)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"hopper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004203217408811462\n",
      "0.005647509451345368\n",
      "0.006314052537679126\n",
      "0.0066377236869957215\n",
      "0.006849729718792066\n",
      "0.007066359671181791\n",
      "0.007340097298979606\n",
      "0.0076887242706275925\n",
      "0.008182330530233067\n",
      "0.009799980680844167\n",
      "0.012406924064512583\n",
      "0.01559505752496649\n",
      "0.019095783543318017\n",
      "0.022720045581553522\n",
      "0.026328720252710054\n",
      "0.02981758284044927\n",
      "0.03310944422579978\n",
      "0.03615029733571118\n",
      "0.038907688412827164\n",
      "0.041378273742380865\n",
      "0.04359207784554041\n",
      "0.045581018938305455\n",
      "0.047372585621378534\n",
      "0.04898525351611534\n",
      "0.05043101407509326\n",
      "0.051723032094286865\n",
      "0.05245039606398572\n",
      "0.05250884942100792\n",
      "0.05224676461160573\n",
      "0.05191024222177236\n",
      "0.05166780635195523\n",
      "0.051627218312042505\n",
      "0.05184752304386134\n",
      "0.052339014219668564\n",
      "0.05302914589620967\n",
      "0.0539047200769457\n",
      "0.05531061924900315\n",
      "0.057198402637849546\n",
      "0.059474608308042645\n",
      "0.06205888490306764\n",
      "0.06487751977244623\n",
      "0.06786117979020931\n",
      "0.07094461776733993\n",
      "0.07406719411528902\n",
      "0.07717365717928447\n",
      "0.08021495745173597\n",
      "0.08314906596352747\n",
      "0.08594186552708927\n",
      "0.0885681645984499\n",
      "0.09101273156820983\n",
      "0.09327104113138403\n",
      "0.09534934268589938\n",
      "0.09724200972381536\n",
      "0.09864827742156827\n",
      "0.09960985421997026\n",
      "0.10031373146420398\n",
      "0.10089919025453026\n",
      "0.10146596658484533\n",
      "0.10208252310460404\n",
      "0.10279201680428952\n",
      "0.10361732456568908\n",
      "0.10459084165967261\n",
      "0.10587915873229882\n",
      "0.1074865427804044\n",
      "0.10936297350813369\n",
      "0.11144713750925071\n",
      "0.11367020027278804\n",
      "0.1159630803084081\n",
      "0.11827388465690773\n",
      "0.12055800097201581\n",
      "0.1227768831746944\n",
      "0.12490219634109678\n",
      "0.12691727953360682\n",
      "0.12881681678243592\n",
      "0.13060534708776406\n",
      "0.13229510775514136\n",
      "0.13390360337309487\n",
      "0.13545119940190473\n",
      "0.13695895265389127\n",
      "0.13844681251658655\n",
      "0.13993226005553372\n",
      "0.14142939934787982\n",
      "0.1429484770491361\n",
      "0.14449578143094166\n",
      "0.14607385777261755\n",
      "0.1476819689061473\n",
      "0.1493167261758702\n",
      "0.1509728168774994\n",
      "0.15264375813905479\n",
      "0.15432261483331786\n",
      "0.15600263118174387\n",
      "0.15767773978313887\n",
      "0.15934292728953978\n",
      "0.1609944513572582\n",
      "0.16262991669686327\n",
      "0.164248228805022\n",
      "0.16584945088243871\n",
      "0.16743459302398\n",
      "0.1690053631817293\n",
      "0.17056390684509148\n",
      "0.17211255859687144\n",
      "0.17365362308737164\n",
      "0.17518919757738652\n",
      "0.17672104273670153\n",
      "0.17825050304411316\n",
      "0.17977847430497432\n",
      "0.18130541248759754\n",
      "0.1828313758680252\n",
      "0.18435609146255122\n",
      "0.1858790360009791\n",
      "0.1873995226821583\n",
      "0.18891678572208667\n",
      "0.19043005635208926\n",
      "0.1919386257993399\n",
      "0.1934418924270417\n",
      "0.194939391985868\n",
      "0.1964308115689028\n",
      "0.19791598905107818\n",
      "0.19939490055789882\n",
      "0.20086763910123354\n",
      "0.20233438755792083\n",
      "0.2037953892499475\n",
      "0.20525091894019715\n",
      "0.20670125631776212\n",
      "0.20814666373929613\n",
      "0.20958736929598798\n",
      "0.21102355558313152\n",
      "0.21245535405330387\n",
      "0.2138828444522875\n",
      "0.2153060584467261\n",
      "0.21672498653251923\n",
      "0.21813958697440602\n",
      "0.21954979573965364\n",
      "0.22095553647969313\n",
      "0.22235672979325463\n",
      "0.22375330112076808\n",
      "0.22514518683954604\n",
      "0.2265323384200992\n",
      "0.22791472463132958\n",
      "0.22929233202964874\n",
      "0.23066516390020747\n",
      "0.23203323806271087\n",
      "0.2333965838473034\n",
      "0.23475523871603124\n",
      "0.23610924484126286\n",
      "0.2374586458177477\n",
      "0.2388034839205271\n",
      "0.24014379789316756\n",
      "0.24147962141900403\n",
      "0.24281098224194522\n",
      "0.24413790193568127\n",
      "0.24546039618570153\n",
      "0.24677847547260623\n",
      "0.24809214609083408\n",
      "0.24940141134012342\n",
      "0.2507062727041532\n",
      "0.2520067309599644\n",
      "0.25330278721132476\n",
      "0.254594443667597\n",
      "0.2558817042127931\n",
      "0.2571645747301976\n",
      "0.25844306321423627\n",
      "0.25971717967985497\n",
      "0.26098693594489136\n",
      "0.26225234530098496\n",
      "0.2635134220803676\n",
      "0.26477018128954827\n",
      "0.2660226381933316\n",
      "0.2672708079429891\n",
      "0.26851470534972677\n",
      "0.2697543446058748\n",
      "0.2709897391606195\n",
      "0.2722209017323244\n",
      "0.27344784429399077\n",
      "0.2746705781435934\n",
      "0.27588911401131405\n",
      "0.27710346219773074\n",
      "0.27831363273723925\n",
      "0.2795196355323915\n",
      "0.2807214804557156\n",
      "0.28191917748743567\n",
      "0.28311273680281207\n",
      "0.28430216877978315\n",
      "0.2854874840277852\n",
      "0.28666869341679246\n",
      "0.2878458080190388\n",
      "0.28901883904569836\n",
      "0.29018779783089843\n",
      "0.29135269581772744\n",
      "0.29251354449192324\n",
      "0.29367035527533614\n",
      "0.2948231395022211\n",
      "0.2959719084736278\n",
      "0.29711667341339176\n",
      "0.29825744542420757\n",
      "0.29939423547814487\n",
      "0.3005270544431671\n",
      "0.30165591310584755\n",
      "0.30278082216291363\n",
      "0.30390179223788527\n",
      "0.30501883396406587\n",
      "0.30613195797614334\n",
      "0.30724117486509717\n",
      "0.30834649522287444\n",
      "0.3094479296795789\n",
      "0.31054548882902594\n",
      "0.31163918326403794\n",
      "0.31272902363628535\n",
      "0.31381502060524\n",
      "0.3148971848247087\n",
      "0.3159755269517476\n",
      "0.3170500575993635\n",
      "0.31812078737017185\n",
      "0.3191877268709116\n",
      "0.32025088669048907\n",
      "0.3213102773882718\n",
      "0.32236590948457\n",
      "0.3234177934458189\n",
      "0.3244659397421565\n",
      "0.32551035881060886\n",
      "0.32655106106684306\n",
      "0.3275880569014854\n",
      "0.32862135664569603\n",
      "0.32965097063527554\n",
      "0.33067690920264264\n",
      "0.33169918266201426\n",
      "0.332717801295174\n",
      "0.33373277538630497\n",
      "0.33474411520970093\n",
      "0.3357518309910946\n",
      "0.33675593300251\n",
      "0.3377564314810776\n",
      "0.33875333665269436\n",
      "0.33974665873947013\n",
      "0.3407364079113522\n",
      "0.3417225943126306\n",
      "0.34270522809036424\n",
      "0.343684319412073\n",
      "0.3446598784158204\n",
      "0.34563191519702186\n",
      "0.34660043978136235\n",
      "0.3475654622319155\n",
      "0.3485269926035588\n",
      "0.34948504091495525\n",
      "0.3504396171723947\n",
      "0.35139073138480065\n",
      "0.3523383935077719\n",
      "0.3532826134832312\n",
      "0.35422340125602847\n",
      "0.35516076675511427\n",
      "0.3560947198790061\n",
      "0.3570252705057466\n",
      "0.3579524285178041\n",
      "0.35887620377543566\n",
      "0.35979660612708536\n",
      "0.3607136454248959\n",
      "0.36162733148359094\n",
      "0.3625376740794872\n",
      "0.3634446829753516\n",
      "0.36434836795214853\n",
      "0.36524873876282865\n",
      "0.36614580511470307\n",
      "0.36703957669005755\n",
      "0.36793006316790294\n",
      "0.36881727427135874\n",
      "0.36970121968174113\n",
      "0.3705819090358311\n",
      "0.37145935196463237\n",
      "0.37233355806686114\n",
      "0.373204536937042\n",
      "0.3740722981565087\n",
      "0.37493685130765275\n",
      "0.3757982059384428\n",
      "0.37665637155469717\n",
      "0.37751135767851113\n",
      "0.3783631738369943\n",
      "0.3792118294968518\n",
      "0.3800573341178471\n",
      "0.38089969714774413\n",
      "0.38173892802127823\n",
      "0.3825750361447287\n",
      "0.3834080309108937\n",
      "0.38423792168426907\n",
      "0.3850647178442506\n",
      "0.38588842876412854\n",
      "0.3867090637562643\n",
      "0.38752663213982763\n",
      "0.3883411432307294\n",
      "0.38915260632950643\n",
      "0.3899610306742912\n",
      "0.3907664254987477\n",
      "0.391568800096321\n",
      "0.39236816368910205\n",
      "0.3931645254583064\n",
      "0.3939578946102051\n",
      "0.3947482803100805\n",
      "0.39553569170365727\n",
      "0.3963201379159614\n",
      "0.3971016280604062\n",
      "0.39788017125128244\n",
      "0.3986557765755147\n",
      "0.3994284531003968\n",
      "0.40019820987109084\n",
      "0.40096505591409254\n",
      "0.4017290002456083\n",
      "0.40249005189184384\n",
      "0.40324821985124437\n",
      "0.40400351308632537\n",
      "0.404755940557175\n",
      "0.40550551122494194\n",
      "0.40625223398951177\n",
      "0.40699611775100986\n",
      "0.4077371713981111\n",
      "0.40847540379790676\n",
      "0.4092108238048291\n",
      "0.40994344024110274\n",
      "0.4106732619312133\n",
      "0.4114002976860166\n",
      "0.4121245563063944\n",
      "0.41284604656917\n",
      "0.4135647772316856\n",
      "0.4142807570049307\n",
      "0.4149939946176157\n",
      "0.4157044987856944\n",
      "0.4164122782033403\n",
      "0.4171173415538109\n",
      "0.41781969746159686\n",
      "0.41851935454892447\n",
      "0.4192163214268959\n",
      "0.41991060668286223\n",
      "0.42060221893130506\n",
      "0.4212911667679216\n",
      "0.4219774587542804\n",
      "0.4226611034309318\n",
      "0.42334210933750105\n",
      "0.4240204849549338\n",
      "0.4246962387223032\n",
      "0.42536937912360984\n",
      "0.4260399146090735\n",
      "0.4267078535934177\n",
      "0.4273732045054284\n",
      "0.42803597574312574\n",
      "0.428696175714621\n",
      "0.42935381278517637\n",
      "0.4300088952768082\n",
      "0.4306614315322395\n",
      "0.4313114298539672\n",
      "0.4319588985421196\n",
      "0.4326038459127433\n",
      "0.4332462802468303\n",
      "0.43388620976203635\n",
      "0.43452364266894095\n",
      "0.43515858719653777\n",
      "0.4357910515324298\n",
      "0.4364210438372103\n",
      "0.43704857228590704\n",
      "0.4376736449920615\n",
      "0.4382962700294136\n",
      "0.43891645551335323\n",
      "0.4395342095335365\n",
      "0.4401495401794555\n",
      "0.44076245552617743\n",
      "0.44137296359407724\n",
      "0.4419810724233552\n",
      "0.44258679005087925\n",
      "0.4431901244552745\n",
      "0.4437910835685063\n",
      "0.4443896753419405\n",
      "0.44498590771239016\n",
      "0.44557978861985165\n",
      "0.4461713259726115\n",
      "0.44676052763086443\n",
      "0.4473474014424323\n",
      "0.44793195526032614\n",
      "0.4485141969094192\n",
      "0.449094134184235\n",
      "0.44967177490594634\n",
      "0.4502471268280066\n",
      "0.45082019766070835\n",
      "0.45139099517700787\n",
      "0.4519595271319502\n",
      "0.4525258012380906\n",
      "0.45308982516442364\n",
      "0.4536516065598512\n",
      "0.4542111530920136\n",
      "0.454768472414605\n",
      "0.45532357214242974\n",
      "0.4558764598710997\n",
      "0.45642714317320343\n",
      "0.4569756296209164\n",
      "0.45752192678408915\n",
      "0.4580660421753031\n",
      "0.45860798330007296\n",
      "0.4591477576747223\n",
      "0.4596853727949537\n",
      "0.46022083610252307\n",
      "0.4607541550381597\n",
      "0.461285337005509\n",
      "0.4618143894125803\n",
      "0.4623413196411015\n",
      "0.4628661350478475\n",
      "0.4633888429900037\n",
      "0.4639094508237901\n",
      "0.46442796585177387\n",
      "0.46494439534914606\n",
      "0.4654587466042385\n",
      "0.46597102689304803\n",
      "0.4664812434814325\n",
      "0.46698940357857505\n",
      "0.46749551437668\n",
      "0.46799958306248896\n",
      "0.46850161682926383\n",
      "0.4690016228639917\n",
      "0.4694996083089471\n",
      "0.4699955802633547\n",
      "0.4704895458248268\n",
      "0.4709815120667124\n",
      "0.4714714860560567\n",
      "0.47195947488111023\n",
      "0.4724454856047645\n",
      "0.4729295252081336\n",
      "0.4734116006554978\n",
      "0.4738917189568731\n",
      "0.47436988709262445\n",
      "0.47484611197685084\n",
      "0.47532040050869295\n",
      "0.4757927596124585\n",
      "0.4762631961634154\n",
      "0.4767317170187325\n",
      "0.47719832904744247\n",
      "0.4776630390890793\n",
      "0.4781258539845238\n",
      "0.47858678054794007\n",
      "0.4790458255622028\n",
      "0.47950299580582556\n",
      "0.4799582980331984\n",
      "0.48041173895488687\n",
      "0.4808633252718565\n",
      "0.4813130636805713\n",
      "0.48176096087580117\n",
      "0.4822070235173236\n",
      "0.4826512582291922\n",
      "0.483093671624903\n",
      "0.4835342703317355\n",
      "0.4839730609605299\n",
      "0.4844100500771187\n",
      "0.4848452442357532\n",
      "0.48527864995123215\n",
      "0.4857102737633562\n",
      "0.48614012216874847\n",
      "0.4865682016317189\n",
      "0.48699451858532133\n",
      "0.48741907949936425\n",
      "0.48784189082023544\n",
      "0.4882629589429699\n",
      "0.4886822902715844\n",
      "0.48909989117279207\n",
      "0.4895157679981309\n",
      "0.4899299271017669\n",
      "0.4903423748230866\n",
      "0.4907531174636375\n",
      "0.4911621613338137\n",
      "0.4915695127175725\n",
      "0.49197517783220385\n",
      "0.49237916292256306\n",
      "0.49278147420222057\n",
      "0.49318211786165034\n",
      "0.4935811001048874\n",
      "0.4939784270788693\n",
      "0.4943741049198552\n",
      "0.4947681397755138\n",
      "0.49516053775999286\n",
      "0.49555130493997024\n",
      "0.49594044742735854\n",
      "0.4963279713058785\n",
      "0.4967138826115855\n",
      "0.4970981873813767\n",
      "0.497480891618493\n",
      "0.49786200130167435\n",
      "0.49824152239520797\n",
      "0.4986194608710994\n",
      "0.4989958226762666\n",
      "0.4993706137492076\n",
      "0.4997438399739414\n",
      "0.5001155072203934\n",
      "0.500485621374046\n",
      "0.5008541842241271\n",
      "0.5012211925728505\n",
      "0.5015866957227876\n",
      "0.5019508480965356\n",
      "0.5023138900591586\n",
      "0.5026760132249479\n",
      "0.5030373696162708\n",
      "0.5033980852043669\n",
      "0.5037582676083944\n",
      "0.5041180106872143\n",
      "0.504477397232111\n",
      "0.5048365006962908\n",
      "0.5051953863393744\n",
      "0.505554112005505\n",
      "0.5059127286462087\n",
      "0.5062712807579607\n",
      "0.5066298067451367\n",
      "0.5069883391563303\n",
      "0.5073469049157079\n",
      "0.5077055255936864\n",
      "0.5080642176061693\n",
      "0.5084229924209422\n",
      "0.5087818567382225\n",
      "0.509140812654259\n",
      "0.5094998578716181\n",
      "0.5098589858560526\n",
      "0.5102181859569814\n",
      "0.5105774435823882\n",
      "0.5109367403165673\n",
      "0.5112960540083258\n",
      "0.5116553589217793\n",
      "0.5120146258293958\n",
      "0.5123738220094882\n",
      "0.5127329113505434\n",
      "0.5130918544515629\n",
      "0.5134506086626068\n",
      "0.5138091281109152\n",
      "0.5141673637784775\n",
      "0.5145252635641097\n",
      "0.5148827723537668\n",
      "0.5152398320655973\n",
      "0.5155963817607637\n",
      "0.5159523577586875\n",
      "0.5163076937233855\n",
      "0.516662320803459\n",
      "0.5170161678253483\n",
      "0.517369161448647\n",
      "0.5177212263867734\n",
      "0.5180722856345854\n",
      "0.5184222606956653\n",
      "0.5187710718857712\n",
      "0.5191186386615376\n",
      "0.519464879866583\n",
      "0.5198097141247308\n",
      "0.5201530601998662\n",
      "0.5204948373473165\n",
      "0.520834965690704\n",
      "0.5211733666158024\n",
      "0.52150996319447\n",
      "0.5218446805101754\n",
      "0.5221774460484679\n",
      "0.5225081901016764\n",
      "0.5228368460792182\n",
      "0.5231633508027549\n",
      "0.5234876448464154\n",
      "0.5238096727441733\n",
      "0.5241293831736057\n",
      "0.5244467291373066\n",
      "0.5247616680366782\n",
      "0.5250741616761077\n",
      "0.5253841762135976\n",
      "0.5256916820608112\n",
      "0.5259966537097206\n",
      "0.5262990694849561\n",
      "0.5265989111073353\n",
      "0.5268961632574609\n",
      "0.5271908130490176\n",
      "0.5274828494091985\n",
      "0.5277722622959027\n",
      "0.5280590418985415\n",
      "0.5283431776976591\n",
      "0.5286246574148536\n",
      "0.5289034659565307\n",
      "0.5291795841758022\n",
      "0.5294529875840932\n",
      "0.5297236449211351\n",
      "0.5299915166729321\n",
      "0.5302565535590273\n",
      "0.5305186948706054\n",
      "0.530777866785841\n",
      "0.5310339805596291\n",
      "0.5312869306341437\n",
      "0.5315365927775779\n",
      "0.5317828221242273\n",
      "0.5320254511413893\n",
      "0.5322642875339101\n",
      "0.5324991121173718\n",
      "0.5327296766824576\n",
      "0.5329557018377636\n",
      "0.533176874765126\n",
      "0.5333928468664533\n",
      "0.533603231549847\n",
      "0.5338076019182894\n",
      "0.5340054884564248\n",
      "0.5341963766499883\n",
      "0.534379704561046\n",
      "0.5345548605055195\n",
      "0.5347211806666532\n",
      "0.5348779466183515\n",
      "0.5350243829333257\n",
      "0.5351596546979563\n",
      "0.5352828650698748\n",
      "0.5353930528530538\n",
      "0.5354891899562447\n",
      "0.5355701789199757\n",
      "0.5356348504968457\n",
      "0.5356819611750816\n",
      "0.5357101906283599\n",
      "0.535718139236667\n",
      "0.5357043257047599\n",
      "0.5356671846045024\n",
      "0.535605063883138\n",
      "0.5355162226403561\n",
      "0.5353988288408579\n",
      "0.5352509570015053\n",
      "0.5350705861078304\n",
      "0.5348555977133163\n",
      "0.5346037741328273\n",
      "0.5343127967933323\n",
      "0.5339802449151495\n",
      "0.5336035943816279\n",
      "0.5331802170344617\n",
      "0.5327073803774343\n",
      "0.5321822477927953\n",
      "0.5316018792415383\n",
      "0.5309632327152324\n",
      "0.5302631664815005\n",
      "0.5294984422381318\n",
      "0.528665729249847\n",
      "0.5277616096994218\n",
      "0.5267825854322\n",
      "0.5257250862376042\n",
      "0.5245854798528181\n",
      "0.5233600838321866\n",
      "0.5220451796793568\n",
      "0.5206370293637448\n",
      "0.5191318943851253\n",
      "0.5175260577398441\n",
      "0.5158158487802237\n",
      "0.5139976714993296\n",
      "0.5120680363006762\n",
      "0.5100235951403005\n",
      "0.5078611804835669\n",
      "0.505577847881711\n",
      "0.5031709226361121\n",
      "0.5006381028730652\n",
      "0.4979776350451277\n",
      "0.4951882799375652\n",
      "0.4922692468585476\n",
      "0.489220182984001\n",
      "0.487591445199781\n",
      "0.48795807897376037\n",
      "0.48926514352488515\n",
      "0.4907669648164964\n",
      "0.4919550801858432\n",
      "0.4927281745320828\n",
      "0.4931092366596124\n",
      "0.49312366500955707\n",
      "0.4927901979775239\n",
      "0.49211922379179657\n",
      "0.4912128765990566\n",
      "0.490340008040451\n",
      "0.489511819783656\n",
      "0.48873600558867003\n",
      "0.48801851331917506\n",
      "0.4873593741923518\n",
      "0.4867523507693586\n",
      "0.4861860675676448\n",
      "0.48564554835672674\n",
      "0.4851136882478259\n",
      "0.4845724780072636\n",
      "0.4840039324783351\n",
      "0.48339073753101497\n",
      "0.48271665474023884\n",
      "0.48196672889086534\n",
      "0.4811273441998288\n",
      "0.4801861689872841\n",
      "0.4791320219886936\n",
      "0.4779546884709676\n",
      "0.47664470920895063\n",
      "0.47519315820998165\n",
      "0.4735914241139956\n",
      "0.47183100733361666\n",
      "0.4699033385291043\n",
      "0.4677996254282077\n",
      "0.4655107338227067\n",
      "0.4630271054537967\n",
      "0.4603387154570083\n",
      "0.45743507295792396\n",
      "0.4543052664874399\n",
      "0.4509380566140586\n",
      "0.44732201928434434\n",
      "0.44344574097003997\n",
      "0.43929806751449024\n",
      "0.4348684093797552\n",
      "0.43014710235936326\n",
      "0.42512582234840784\n",
      "0.41979805135131476\n",
      "0.4141595868861318\n",
      "0.4082090853544524\n",
      "0.40194862710382134\n",
      "0.3953842891894061\n",
      "0.3885237013950677\n",
      "0.3813229003562335\n",
      "0.3737310575509763\n",
      "0.3657593944517125\n",
      "0.3574234188528521\n",
      "0.34874261000460594\n",
      "0.33974030625743085\n",
      "0.3304436016746397\n",
      "0.3208832607449171\n",
      "0.3110936585230031\n",
      "0.3011127518021613\n",
      "0.2909820863801424\n",
      "0.2807468441712119\n",
      "0.27045593362916415\n",
      "0.2601621245861622\n",
      "0.2513943424262562\n",
      "0.2465376572496441\n",
      "0.24368783699424781\n",
      "0.24228238178702657\n",
      "0.24201714218545908\n",
      "0.2425938686826652\n",
      "0.2437415920155179\n",
      "0.2452751318597208\n",
      "0.24699871753144523\n",
      "0.24873238374226334\n",
      "0.2503916508794471\n",
      "0.2519635491136175\n",
      "0.25344483672774504\n",
      "0.25484017508856704\n",
      "0.256161383913518\n",
      "0.25742605937886015\n",
      "0.2586562487886035\n",
      "0.2598773255300606\n",
      "0.26111702762603495\n",
      "0.2624045841148016\n",
      "0.2637698659169546\n",
      "0.26524252465821985\n",
      "0.2668511091615381\n",
      "0.2686221762145177\n",
      "0.27125513516542815\n",
      "0.2777651327496907\n",
      "0.2877415303053647\n",
      "0.29907733261115793\n",
      "0.3094603808959262\n",
      "0.31749951269831994\n",
      "0.3252632943636044\n",
      "0.33272023489992403\n",
      "0.33857902336705253\n",
      "0.3433189286880407\n",
      "0.3476145036524031\n",
      "0.35173800037916914\n",
      "0.3554730195638248\n",
      "0.35921866087538623\n",
      "0.3632829029833495\n",
      "0.36756570009473727\n",
      "0.3720379569633214\n",
      "0.3766932997047787\n",
      "0.3815170953586793\n",
      "0.38649327635141884\n",
      "0.39160691715568763\n",
      "0.39683563996159454\n",
      "0.40214722664724284\n",
      "0.4075092831356623\n",
      "0.4129055137552661\n",
      "0.41833583515000194\n",
      "0.4237977811866516\n",
      "0.4292575682624379\n",
      "0.4346013158305292\n",
      "0.4397961836753098\n",
      "0.44484074950878877\n",
      "0.44973848289438423\n",
      "0.45449190334709927\n",
      "0.4591006706412136\n",
      "0.46356118923828676\n",
      "0.4678667742490591\n",
      "0.4720270925492461\n",
      "0.4763403454917897\n",
      "0.4808208695738547\n",
      "0.48532517017153576\n",
      "0.489748860140252\n",
      "0.4940277939623831\n",
      "0.49813903592590253\n",
      "0.5020838195382437\n",
      "0.505865669236595\n",
      "0.5094799931704023\n",
      "0.5128685948026367\n",
      "0.516029823678015\n",
      "0.5189822711201101\n",
      "0.5217412808669316\n",
      "0.5243182193418714\n",
      "0.5267209336126452\n",
      "0.5289546101938206\n",
      "0.5311718552433268\n",
      "0.5334813217028584\n",
      "0.5357965324121121\n",
      "0.5380718075856684\n",
      "0.5402867143755247\n",
      "0.5424349769657031\n",
      "0.5445177562870677\n",
      "0.5465397062704147\n",
      "0.54850675187242\n",
      "0.5504249093952667\n",
      "0.5522997217090355\n",
      "0.5541360425086397\n",
      "0.5559380070572936\n",
      "0.5577090926328009\n",
      "0.559452213348\n",
      "0.5611698193679612\n",
      "0.562863986431791\n",
      "0.5645366052011574\n",
      "0.5661895172906957\n",
      "0.5678242352086076\n",
      "0.5694419559995801\n",
      "0.5710436459179414\n",
      "0.5726301060716841\n",
      "0.5742020189883374\n",
      "0.5757599793555975\n",
      "0.5773045139724184\n",
      "0.5788360944864696\n",
      "0.580355145303766\n",
      "0.5818620489593781\n",
      "0.5833571502157884\n",
      "0.5848407592091824\n",
      "0.5863131544172007\n",
      "0.5877745854181942\n",
      "0.5892252756579666\n",
      "0.5906654249082529\n",
      "0.5920952116552708\n",
      "0.5935147956492156\n",
      "0.5949243197228431\n",
      "0.5963239118561896\n",
      "0.5977136871190334\n",
      "0.5990937488992035\n",
      "0.6004641903381488\n",
      "0.6018250956722541\n",
      "0.6031765660897976\n",
      "0.6045188156931617\n",
      "0.605852042040456\n",
      "0.6071763658516431\n",
      "0.6084918583732878\n",
      "0.6097985618612758\n",
      "0.6110965031215201\n",
      "0.6123857021842981\n",
      "0.6136661771232529\n",
      "0.614937946482909\n",
      "0.6162010304430932\n",
      "0.6174554512535843\n",
      "0.6187012333901409\n",
      "0.619938403329466\n",
      "0.6211669895231379\n",
      "0.6223870222768374\n",
      "0.6235985334442803\n",
      "0.6248015563698991\n",
      "0.6259961258253988\n",
      "0.627182277983917\n",
      "0.6283600501582555\n",
      "0.6295294805410698\n",
      "0.6306906083468078\n",
      "0.6318434735354174\n",
      "0.6329881168845988\n",
      "0.6341245799657307\n",
      "0.6352529047215674\n",
      "0.6363731335857071\n",
      "0.6374853093515287\n",
      "0.6385894751136679\n",
      "0.6396856744462376\n",
      "0.6407739511717621\n",
      "0.641854349063937\n",
      "0.6429269120048273\n",
      "0.6439916839219102\n",
      "0.6450487088270346\n",
      "0.6460980308705709\n",
      "0.6471396941221955\n",
      "0.6481737426150205\n",
      "0.6492002202573137\n",
      "0.650219170975611\n",
      "0.6512306387194406\n",
      "0.6522346672079696\n",
      "0.6532313000043833\n",
      "0.654220580637988\n",
      "0.6552025526285767\n",
      "0.6561772592962315\n",
      "0.6571447439002454\n",
      "0.6581050495805049\n",
      "0.6590582192003966\n",
      "0.6600042955804549\n",
      "0.6609433214282987\n",
      "0.6618753392178753\n",
      "0.6628003912822813\n",
      "0.6637185199482742\n",
      "0.6646297673943158\n",
      "0.6655341755903823\n",
      "0.6664317863982582\n",
      "0.6673226415495599\n",
      "0.6682067826603377\n",
      "0.6690842510714472\n",
      "0.6699550879833989\n",
      "0.6708193345865848\n",
      "0.6716770318489103\n",
      "0.6725282204870614\n",
      "0.6733729412092533\n",
      "0.6742112344992367\n",
      "0.6750431405255236\n",
      "0.6758686995667831\n",
      "0.6766879517068615\n",
      "0.6775009367576209\n",
      "0.6783076944531194\n",
      "0.6791082642849191\n",
      "0.6799026857006958\n",
      "0.6806909980053747\n",
      "0.6814732402089873\n",
      "0.6822494511851724\n",
      "0.683019669783283\n",
      "0.683783934513111\n",
      "0.6845422837300719\n",
      "0.6852947557610096\n",
      "0.6860413887670712\n",
      "0.6867822207364074\n",
      "0.6875172894833947\n",
      "0.6882466326821163\n",
      "0.6889702878049976\n",
      "0.6896882921603444\n",
      "0.6904006828817046\n",
      "0.6911074969034164\n",
      "0.69180877097629\n",
      "0.6925045418063892\n",
      "0.693194846002764\n",
      "0.693879719880523\n",
      "0.694559199580883\n",
      "0.695233321089858\n",
      "0.6959021202535278\n",
      "0.6965656328271222\n",
      "0.6972238943295735\n",
      "0.6978769400896674\n",
      "0.6985248052845141\n",
      "0.6991675249541831\n",
      "0.6998051339367869\n",
      "0.7004376668711254\n",
      "0.7010651583442947\n",
      "0.7016876427127219\n",
      "0.7023051541713603\n",
      "0.7029177268618412\n",
      "0.70352539456974\n",
      "0.7041281909377944\n",
      "0.7047261495828201\n",
      "0.7053193039017635\n",
      "0.7059076871494473\n",
      "0.7064913322964502\n",
      "0.7070702721417369\n",
      "0.7076445394840606\n",
      "0.708214166969738\n",
      "0.7087791870057408\n",
      "0.7093396317560711\n",
      "0.7098955333537291\n",
      "0.7104469236771765\n",
      "0.7109938344850567\n",
      "0.7115362973330523\n",
      "0.7120743435412958\n",
      "0.7126080043836293\n",
      "0.7131373109933\n",
      "0.7136622942713675\n",
      "0.7141829849221879\n",
      "0.7146994137114929\n",
      "0.7152116111493572\n",
      "0.7157196073227613\n",
      "0.7162234322993647\n",
      "0.7167231161253899\n",
      "0.7172186884914318\n",
      "0.7177101790040706\n",
      "0.7181976171775007\n",
      "0.7186810323557494\n",
      "0.7191604537621128\n",
      "0.7196359103980702\n",
      "0.7201074309945846\n",
      "0.7205750442042558\n",
      "0.7210387785676573\n",
      "0.721498662534668\n",
      "0.721954724338554\n",
      "0.7224069919573342\n",
      "0.7228554932678384\n",
      "0.7233002558486002\n",
      "0.7237413071643558\n",
      "0.7241786747295382\n",
      "0.7246123859295422\n",
      "0.7250424678310952\n",
      "0.7254689473672917\n",
      "0.7258918512727429\n",
      "0.7263112061561853\n",
      "0.726727038514158\n",
      "0.7271393746201101\n",
      "0.7275482406134508\n",
      "0.7279536625411142\n",
      "0.7283556662362378\n",
      "0.7287542774622902\n",
      "0.7291495217518298\n",
      "0.7295414243555229\n",
      "0.7299300105936172\n",
      "0.730315305671331\n",
      "0.7306973343896936\n",
      "0.7310761214204475\n",
      "0.7314516914692211\n",
      "0.0007493510547056936\n",
      "Episode finished after 1000 timesteps\n"
     ]
    }
   ],
   "source": [
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "\n",
    "writer = imageio.get_writer('hopper-flip.mp4', fps=100)\n",
    "\n",
    "N_step = 100000\n",
    "for i in range(N_step):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    print(obs[0][1])\n",
    "    writer.append_data(vec_env.render(\"rgb_array\"))\n",
    "    #VecEnv resets automatically\n",
    "    if done:\n",
    "      print(\"Episode finished after {} timesteps\".format(i+1))\n",
    "      break\n",
    "      obs = vec_env.reset()\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# d = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "# current_py_file = os.getcwd() + '/hopper.ipynb'\n",
    "# new_py_file = os.getcwd() + '/Run/hopper%s.ipynb'%(d)\n",
    "\n",
    "# shutil.copyfile(current_py_file, new_py_file)\n",
    "# shutil.copyfile('hopper-flip.mp4', os.getcwd()+'/Render/hopper-flip%s.mp4'%(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5707963267948966"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
