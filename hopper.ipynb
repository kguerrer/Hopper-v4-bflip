{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import imageio\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRewardWrapper(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(CustomRewardWrapper, self).__init__(env)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, truncated, info = self.env.step(action)\n",
    "        # Access relevant state and action variables\n",
    "        \n",
    "        #state\n",
    "        z = obs[0]                  # Height of the robot\n",
    "        a = obs[1]                  # Angle of the robot\n",
    "        a_hip = obs[2]              # Angle of the hip\n",
    "        a_knee = obs[3]             # Angle of the knee\n",
    "        a_ankle = obs[4]            # Angle of the ankle\n",
    "        v_x = obs[5]                # Velocity in x direction\n",
    "        v_z = obs[6]                # Velocity in z direction\n",
    "        a_d = obs[7]                # Angular velocity \n",
    "        a_hip_d = obs[8]            # Angular velocity of the hip\n",
    "        a_knee_d = obs[9]           # Angular velocity of the knee\n",
    "        a_ankle_d = obs[10]         # Angular velocity of the ankle\n",
    "        \n",
    "        #action\n",
    "        torque_hip = action[0]      # Torque applied to the hip\n",
    "        torque_knee = action[1]     # Torque applied to the knee\n",
    "        torque_ankle = action[2]    # Torque applied to the ankle\n",
    "\n",
    "        #different criteria for reward\n",
    "        energy_used = np.sum(np.square(action))  # Simplistic energy calculation\n",
    "\n",
    "        # Custom reward logic\n",
    "        custom_reward = np.tanh(a) * 0.5                           # Reward for positive angles\n",
    "        custom_reward += 5*np.exp(-(a-(2*np.pi))**2/(2*np.pi))      # Reward for 2pi angle\n",
    "        custom_reward -= energy_used * 0.1                          # Penalize energy consumption\n",
    "\n",
    "        # used by openai\n",
    "        # backroll = -obs[7]\n",
    "        # height = obs[0]\n",
    "        # vel_act = action[0] * obs[8] + action[1] * obs[9] + a[2] * obs[10]\n",
    "        # backslide = -obs[5]\n",
    "        # reward = backroll * (1.0 + .3 * height + .1 * vel_act + .05 * backslide)\n",
    "\n",
    "        if done:\n",
    "            custom_reward -= 8  # Heavy penalty for falling\n",
    "\n",
    "        return obs, custom_reward, done, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 43.6     |\n",
      "|    ep_rew_mean     | -20.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 1051     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 56.3        |\n",
      "|    ep_rew_mean          | -21.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 573         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010734132 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.01        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.482       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 8.62        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 64.2       |\n",
      "|    ep_rew_mean          | -21.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 430        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00874982 |\n",
      "|    clip_fraction        | 0.0802     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.17      |\n",
      "|    explained_variance   | 0.622      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.11       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    std                  | 0.965      |\n",
      "|    value_loss           | 3.51       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.3        |\n",
      "|    ep_rew_mean          | -21.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 390         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008017914 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.957       |\n",
      "|    value_loss           | 4.05        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "healthy_reward = 0.8\n",
    "healthy_z_range = (0.2, float(\"inf\"))\n",
    "healthy_angle_range = (-np.pi/4, 2*np.pi+np.pi/4)\n",
    "reset_noise_scale = 5e-3\n",
    "exclude_current_positions_from_observation = True\n",
    "\n",
    "env = gym.make('Hopper-v4', render_mode='rgb_array', healthy_reward=healthy_reward, healthy_z_range=healthy_z_range, healthy_angle_range=healthy_angle_range, reset_noise_scale=reset_noise_scale, exclude_current_positions_from_observation=exclude_current_positions_from_observation)\n",
    "env = CustomRewardWrapper(env)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "n_learning_steps = 30000\n",
    "model.learn(total_timesteps=n_learning_steps)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"hopper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002712728331846149\n",
      "0.003643348925547453\n",
      "0.005009833826853255\n",
      "0.00669379838812032\n",
      "0.008519238191886751\n",
      "0.010150073683339244\n",
      "0.012126839992988393\n",
      "0.015466671364019892\n",
      "0.020319317846429676\n",
      "0.02682366905210253\n",
      "0.03506038534687783\n",
      "0.04509949772585869\n",
      "0.05678373432564986\n",
      "0.06996311245834766\n",
      "0.08473488394667411\n",
      "0.10050663630803938\n",
      "0.11635951184434361\n",
      "0.13235464459695637\n",
      "0.14829309880288255\n",
      "0.1616785263647102\n",
      "0.17341569054727\n",
      "0.18434811869630574\n",
      "0.19494202406142122\n",
      "0.205442842027757\n",
      "0.21597003671781342\n",
      "0.22657342031107447\n",
      "0.23726602676353553\n",
      "0.24804289831330079\n",
      "0.25889149926581756\n",
      "0.2697972350538747\n",
      "0.2807461680100874\n",
      "0.2917261723882001\n",
      "0.3027272700483812\n",
      "0.31374213293786163\n",
      "0.3247661334394311\n",
      "0.33579536378729874\n",
      "0.346825847620062\n",
      "0.3578536924092507\n",
      "0.3688754174066022\n",
      "0.37988814913621605\n",
      "0.39088962010053685\n",
      "0.4018780209154528\n",
      "0.41285178513997833\n",
      "0.4238093698860712\n",
      "0.43474906651957174\n",
      "0.4456688523274343\n",
      "0.45656627879305156\n",
      "0.4674383873586353\n",
      "0.47828165475098755\n",
      "0.4890919627009706\n",
      "0.499864590306448\n",
      "0.510594231552778\n",
      "0.5212750391203633\n",
      "0.5319006914475848\n",
      "0.542431203144913\n",
      "0.5527745727010702\n",
      "0.5629362094057124\n",
      "0.5720126234976713\n",
      "0.5806558169539666\n",
      "0.5893284551076501\n",
      "0.5982074000303252\n",
      "0.6073301738690522\n",
      "0.6166687285297446\n",
      "0.6261696708504141\n",
      "0.6357763318118295\n",
      "0.6454402022351552\n",
      "0.6551264529447122\n",
      "0.6648156983916738\n",
      "0.6745018075830149\n",
      "0.6841888925035218\n",
      "0.6938884452166382\n",
      "0.7036167141882274\n",
      "0.7133925696176032\n",
      "0.7232358423841551\n",
      "0.7331659876620924\n",
      "0.7432011346736869\n",
      "0.7533575265046815\n",
      "0.7636492114890385\n",
      "0.7740878839901486\n",
      "0.7846828626208223\n",
      "0.7954411666995794\n",
      "0.806367653004033\n",
      "0.8174651814875498\n",
      "0.8287347861197968\n",
      "0.8401758343001552\n",
      "0.8517861644998646\n",
      "0.86356219679967\n",
      "0.8754990144258352\n",
      "0.8875904164871895\n",
      "0.8998289434711095\n",
      "0.9122058774088662\n",
      "0.9247112186164037\n",
      "0.9373336404285876\n",
      "0.9500604228410389\n",
      "0.9628773654334741\n",
      "0.9757686794467215\n",
      "0.9887168586345262\n",
      "1.0017025286189096\n",
      "1.0147042748425217\n",
      "1.0276984500039823\n",
      "1.04065896303997\n",
      "1.053557053601712\n",
      "1.066361058520687\n",
      "1.0790361801378143\n",
      "1.0915442722260247\n",
      "1.1038436671322327\n",
      "1.1158890795258014\n",
      "1.1276316371134076\n",
      "1.1390191057283057\n",
      "1.1499963910597346\n",
      "1.1605064168055308\n",
      "1.170500846329012\n",
      "1.1799524841718674\n",
      "1.1888317039937963\n",
      "1.1971043071438325\n",
      "1.2047338156518848\n",
      "1.2116838657550049\n",
      "1.217920646339648\n",
      "1.2234354838458157\n",
      "1.22832562102806\n",
      "1.2326520151283902\n",
      "1.2363259239804645\n",
      "1.2392619272500656\n",
      "1.2413864720854506\n",
      "1.2426418180221004\n",
      "1.242985391831414\n",
      "1.2423855284619754\n",
      "1.2416389118657534\n",
      "1.2405219331603088\n",
      "1.237947967376487\n",
      "1.2334592205542314\n",
      "1.226883940814673\n",
      "1.218193794020585\n",
      "1.207491207801548\n",
      "1.194992325471175\n",
      "1.1809689262343286\n",
      "1.1656933932526639\n",
      "1.1494117955531762\n",
      "1.132334856406955\n",
      "1.1146387468374055\n",
      "1.096469569208453\n",
      "1.0779485245876665\n",
      "1.059176617030995\n",
      "1.0402385751564092\n",
      "1.0212059938349038\n",
      "1.0021398080130344\n",
      "0.9830922333674413\n",
      "0.9669128193602003\n",
      "0.968056445197374\n",
      "0.9788409884986745\n",
      "0.9936132699162336\n",
      "1.010184014141103\n",
      "1.0273232124542762\n",
      "1.0444094879979884\n",
      "1.0611571304771905\n",
      "1.0774366556165864\n",
      "1.0931822756850316\n",
      "1.1083479007351362\n",
      "1.1228885869567642\n",
      "1.1367537037312052\n",
      "1.1498860322370748\n",
      "1.1622254263674658\n",
      "1.1737175168052274\n",
      "1.1843266666529098\n",
      "1.1940473736750596\n",
      "1.2029046999032282\n",
      "1.2109422063767017\n",
      "1.218208233368007\n",
      "1.2247492505607118\n",
      "1.230608653804175\n",
      "1.2358267779105254\n",
      "1.240440726721528\n",
      "1.2444845814718426\n",
      "1.247990130909829\n",
      "1.2509870571140977\n",
      "1.2535029075956696\n",
      "1.2555740763465668\n",
      "1.2572255920849924\n",
      "1.2584680920011704\n",
      "1.2593189889866816\n",
      "1.2597957781234221\n",
      "1.2599149716099671\n",
      "1.2596920212544134\n",
      "1.2591415120485563\n",
      "1.2582774297121908\n",
      "1.2571134108149296\n",
      "1.2556637139208413\n",
      "1.2539695438312968\n",
      "1.2521090718298031\n",
      "1.2501854561742782\n",
      "1.2483729537226638\n",
      "1.2467731269921694\n",
      "1.2454804932102033\n",
      "1.2446003895905737\n",
      "1.2442482629667593\n",
      "1.2445485306030035\n",
      "1.245632813631896\n",
      "1.2476372373895135\n",
      "1.250698364883034\n",
      "1.2549471845842044\n",
      "1.2605004270059001\n",
      "1.2738284554744532\n",
      "1.2979165222889175\n",
      "1.3281569555026156\n",
      "1.3621821978523951\n",
      "-0.0006833813382613541\n",
      "Episode finished after 206 timesteps\n"
     ]
    }
   ],
   "source": [
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "\n",
    "writer = imageio.get_writer('hopper-flip.mp4', fps=100)\n",
    "\n",
    "N_step = 100000\n",
    "for i in range(N_step):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    print(obs[0][1])\n",
    "    writer.append_data(vec_env.render(\"rgb_array\"))\n",
    "    #VecEnv resets automatically\n",
    "    if done:\n",
    "      print(\"Episode finished after {} timesteps\".format(i+1))\n",
    "      break\n",
    "      obs = vec_env.reset()\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# d = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "# current_py_file = os.getcwd() + '/hopper.ipynb'\n",
    "# new_py_file = os.getcwd() + '/Run/hopper%s.ipynb'%(d)\n",
    "\n",
    "# shutil.copyfile(current_py_file, new_py_file)\n",
    "# shutil.copyfile('hopper-flip.mp4', os.getcwd()+'/Render/hopper-flip%s.mp4'%(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5707963267948966"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
